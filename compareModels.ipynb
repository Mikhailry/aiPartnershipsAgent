{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.my_llm_utils import *\n",
    "from utils.my_utils import *\n",
    "from utils.tavily_search_utils import web_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = \"data/AI Partnerships sample_updated.csv\"\n",
    "\n",
    "# read the csv file\n",
    "df, output_path = read_csv_with_output_path(csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gemma3:1b\n"
     ]
    }
   ],
   "source": [
    "# # load the LLM\n",
    "\n",
    "# # for default llm\n",
    "# #llm = get_llm()\n",
    "\n",
    "# # for openai llm\n",
    "# #llm = get_llm(use_openai=True, model_name=\"gpt-4o\")\n",
    "\n",
    "# # for ollama llm - [gemma3:1b, llama3.2:latest, deepseek-r1:8b, phi4:latest]\n",
    "# llm = get_llm(use_openai=False, model_name=\"gemma3:1b\")\n",
    "\n",
    "\n",
    "# # Check which llm has been loaded\n",
    "# if hasattr(llm, 'model'):\n",
    "# \tprint(llm.model)  # check loaded model\n",
    "# else:\n",
    "# \tprint(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmikhailry\u001b[0m (\u001b[33mmikhailry-paylocity\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/Dev/Library/Mobile Documents/com~apple~CloudDocs/Documents/coding/aiPartnershipsAgent/wandb/run-20250504_093310-v5ed4sri</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mikhailry-paylocity/AI-Partnerships-agent/runs/v5ed4sri' target=\"_blank\">elegant-republic-3</a></strong> to <a href='https://wandb.ai/mikhailry-paylocity/AI-Partnerships-agent' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mikhailry-paylocity/AI-Partnerships-agent' target=\"_blank\">https://wandb.ai/mikhailry-paylocity/AI-Partnerships-agent</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mikhailry-paylocity/AI-Partnerships-agent/runs/v5ed4sri' target=\"_blank\">https://wandb.ai/mikhailry-paylocity/AI-Partnerships-agent/runs/v5ed4sri</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/mikhailry-paylocity/AI-Partnerships-agent/runs/v5ed4sri?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x10de659d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.init(project=\"AI-Partnerships-agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ollamaModels = [\"gemma3:1b\", \"llama3.2:latest\", \"phi4:latest\"]\n",
    "openAiModels = [\"gpt-4o\"]\n",
    "\n",
    "prompt = f\"\"\"\n",
    "    Summarize the following AI partnership announcement in one sentence:\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing gemma3:1b...\n",
      "\n",
      "Processing llama3.2:latest...\n",
      "\n",
      "Processing phi4:latest...\n",
      "\n",
      "Processing gpt-4o...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'AIMessage' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/AI_agents/lib/python3.11/site-packages/pandas/core/indexes/base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'gpt-4o_summary'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/AI_agents/lib/python3.11/site-packages/pandas/core/frame.py:4561\u001b[39m, in \u001b[36mDataFrame._set_value\u001b[39m\u001b[34m(self, index, col, value, takeable)\u001b[39m\n\u001b[32m   4560\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4561\u001b[39m     icol = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4562\u001b[39m     iindex = \u001b[38;5;28mself\u001b[39m.index.get_loc(index)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/AI_agents/lib/python3.11/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n",
      "\u001b[31mKeyError\u001b[39m: 'gpt-4o_summary'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 54\u001b[39m\n\u001b[32m     51\u001b[39m process_model_summaries(ollamaModels, use_openai=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     53\u001b[39m \u001b[38;5;66;03m# Process OpenAI models\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m \u001b[43mprocess_model_summaries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopenAiModels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_openai\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# Create summary DataFrame\u001b[39;00m\n\u001b[32m     57\u001b[39m summary_stats = pd.DataFrame({\n\u001b[32m     58\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mModel\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28mlist\u001b[39m(model_stats.keys()),\n\u001b[32m     59\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mTotal Time (s)\u001b[39m\u001b[33m'\u001b[39m: [stats[\u001b[33m'\u001b[39m\u001b[33mtotal_time\u001b[39m\u001b[33m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m stats \u001b[38;5;129;01min\u001b[39;00m model_stats.values()],\n\u001b[32m   (...)\u001b[39m\u001b[32m     67\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mMedian Length\u001b[39m\u001b[33m'\u001b[39m: [stats[\u001b[33m'\u001b[39m\u001b[33mmedian_length\u001b[39m\u001b[33m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m stats \u001b[38;5;129;01min\u001b[39;00m model_stats.values()]\n\u001b[32m     68\u001b[39m })\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 36\u001b[39m, in \u001b[36mprocess_model_summaries\u001b[39m\u001b[34m(models, use_openai)\u001b[39m\n\u001b[32m     33\u001b[39m     model_stats[model][\u001b[33m'\u001b[39m\u001b[33mprocessing_times\u001b[39m\u001b[33m'\u001b[39m].append(end_time - start_time)\n\u001b[32m     35\u001b[39m     \u001b[38;5;66;03m# add the summary to the dataframe\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m     \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mat\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m_summary\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m = summary\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m# Calculate final statistics\u001b[39;00m\n\u001b[32m     39\u001b[39m model_stats[model][\u001b[33m'\u001b[39m\u001b[33mend_time\u001b[39m\u001b[33m'\u001b[39m] = datetime.now()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/AI_agents/lib/python3.11/site-packages/pandas/core/indexing.py:2586\u001b[39m, in \u001b[36m_AtIndexer.__setitem__\u001b[39m\u001b[34m(self, key, value)\u001b[39m\n\u001b[32m   2583\u001b[39m     \u001b[38;5;28mself\u001b[39m.obj.loc[key] = value\n\u001b[32m   2584\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2586\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__setitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/AI_agents/lib/python3.11/site-packages/pandas/core/indexing.py:2542\u001b[39m, in \u001b[36m_ScalarAccessIndexer.__setitem__\u001b[39m\u001b[34m(self, key, value)\u001b[39m\n\u001b[32m   2539\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(key) != \u001b[38;5;28mself\u001b[39m.ndim:\n\u001b[32m   2540\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNot enough indexers for scalar access (setting)!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m2542\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_set_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtakeable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_takeable\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/AI_agents/lib/python3.11/site-packages/pandas/core/frame.py:4575\u001b[39m, in \u001b[36mDataFrame._set_value\u001b[39m\u001b[34m(self, index, col, value, takeable)\u001b[39m\n\u001b[32m   4573\u001b[39m         \u001b[38;5;28mself\u001b[39m.iloc[index, col] = value\n\u001b[32m   4574\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4575\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m = value\n\u001b[32m   4576\u001b[39m     \u001b[38;5;28mself\u001b[39m._item_cache.pop(col, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m   4578\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidIndexError \u001b[38;5;28;01mas\u001b[39;00m ii_err:\n\u001b[32m   4579\u001b[39m     \u001b[38;5;66;03m# GH48729: Seems like you are trying to assign a value to a\u001b[39;00m\n\u001b[32m   4580\u001b[39m     \u001b[38;5;66;03m# row when only scalar options are permitted\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/AI_agents/lib/python3.11/site-packages/pandas/core/indexing.py:911\u001b[39m, in \u001b[36m_LocationIndexer.__setitem__\u001b[39m\u001b[34m(self, key, value)\u001b[39m\n\u001b[32m    908\u001b[39m \u001b[38;5;28mself\u001b[39m._has_valid_setitem_indexer(key)\n\u001b[32m    910\u001b[39m iloc = \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.name == \u001b[33m\"\u001b[39m\u001b[33miloc\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.obj.iloc\n\u001b[32m--> \u001b[39m\u001b[32m911\u001b[39m \u001b[43miloc\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_setitem_with_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/AI_agents/lib/python3.11/site-packages/pandas/core/indexing.py:1890\u001b[39m, in \u001b[36m_iLocIndexer._setitem_with_indexer\u001b[39m\u001b[34m(self, indexer, value, name)\u001b[39m\n\u001b[32m   1885\u001b[39m         \u001b[38;5;28mself\u001b[39m.obj[key] = infer_fill_value(value)\n\u001b[32m   1887\u001b[39m     new_indexer = convert_from_missing_indexer_tuple(\n\u001b[32m   1888\u001b[39m         indexer, \u001b[38;5;28mself\u001b[39m.obj.axes\n\u001b[32m   1889\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1890\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_setitem_with_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_indexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1892\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m   1894\u001b[39m \u001b[38;5;66;03m# reindex the axis\u001b[39;00m\n\u001b[32m   1895\u001b[39m \u001b[38;5;66;03m# make sure to clear the cache because we are\u001b[39;00m\n\u001b[32m   1896\u001b[39m \u001b[38;5;66;03m# just replacing the block manager here\u001b[39;00m\n\u001b[32m   1897\u001b[39m \u001b[38;5;66;03m# so the object is the same\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/AI_agents/lib/python3.11/site-packages/pandas/core/indexing.py:1942\u001b[39m, in \u001b[36m_iLocIndexer._setitem_with_indexer\u001b[39m\u001b[34m(self, indexer, value, name)\u001b[39m\n\u001b[32m   1939\u001b[39m \u001b[38;5;66;03m# align and set the values\u001b[39;00m\n\u001b[32m   1940\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m take_split_path:\n\u001b[32m   1941\u001b[39m     \u001b[38;5;66;03m# We have to operate column-wise\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1942\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_setitem_with_indexer_split_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1943\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1944\u001b[39m     \u001b[38;5;28mself\u001b[39m._setitem_single_block(indexer, value, name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/AI_agents/lib/python3.11/site-packages/pandas/core/indexing.py:1984\u001b[39m, in \u001b[36m_iLocIndexer._setitem_with_indexer_split_path\u001b[39m\u001b[34m(self, indexer, value, name)\u001b[39m\n\u001b[32m   1979\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m np.ndim(value) == \u001b[32m2\u001b[39m:\n\u001b[32m   1980\u001b[39m     \u001b[38;5;66;03m# TODO: avoid np.ndim call in case it isn't an ndarray, since\u001b[39;00m\n\u001b[32m   1981\u001b[39m     \u001b[38;5;66;03m#  that will construct an ndarray, which will be wasteful\u001b[39;00m\n\u001b[32m   1982\u001b[39m     \u001b[38;5;28mself\u001b[39m._setitem_with_indexer_2d_value(indexer, value)\n\u001b[32m-> \u001b[39m\u001b[32m1984\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(ilocs) == \u001b[32m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m lplane_indexer == \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scalar(pi):\n\u001b[32m   1985\u001b[39m     \u001b[38;5;66;03m# We are setting multiple rows in a single column.\u001b[39;00m\n\u001b[32m   1986\u001b[39m     \u001b[38;5;28mself\u001b[39m._setitem_single_column(ilocs[\u001b[32m0\u001b[39m], value, pi)\n\u001b[32m   1988\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(ilocs) == \u001b[32m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[32m0\u001b[39m != lplane_indexer != \u001b[38;5;28mlen\u001b[39m(value):\n\u001b[32m   1989\u001b[39m     \u001b[38;5;66;03m# We are trying to set N values into M entries of a single\u001b[39;00m\n\u001b[32m   1990\u001b[39m     \u001b[38;5;66;03m#  column, which is invalid for N != M\u001b[39;00m\n\u001b[32m   1991\u001b[39m     \u001b[38;5;66;03m# Exclude zero-len for e.g. boolean masking that is all-false\u001b[39;00m\n",
      "\u001b[31mTypeError\u001b[39m: object of type 'AIMessage' has no len()"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# Initialize statistics dictionary\n",
    "model_stats = {}\n",
    "\n",
    "def process_model_summaries(models, use_openai=False):\n",
    "    for model in models:\n",
    "        print(f\"\\nProcessing {model}...\")\n",
    "        llm = get_llm(use_openai=use_openai, model_name=model)\n",
    "        \n",
    "        # Initialize statistics for this model\n",
    "        model_stats[model] = {\n",
    "            'summary_lengths': [],\n",
    "            'processing_times': [],\n",
    "            'start_time': datetime.now()\n",
    "        }\n",
    "        \n",
    "        # iterate over the rows of the dataframe\n",
    "        for index, row in df.iterrows():\n",
    "            # get the raw content\n",
    "            raw_content = row['raw_content']\n",
    "            \n",
    "            # Time the summarization\n",
    "            start_time = time.time()\n",
    "            # summarize the raw content\n",
    "            summary = llm.invoke(prompt + \"\\n\" + raw_content)\n",
    "            end_time = time.time()\n",
    "            \n",
    "            # Store statistics\n",
    "            model_stats[model]['summary_lengths'].append(len(str(summary)))\n",
    "            model_stats[model]['processing_times'].append(end_time - start_time)\n",
    "            \n",
    "            # add the summary to the dataframe\n",
    "            df.at[index, model + '_summary'] = summary\n",
    "            \n",
    "        # Calculate final statistics\n",
    "        model_stats[model]['end_time'] = datetime.now()\n",
    "        model_stats[model]['total_time'] = (model_stats[model]['end_time'] - model_stats[model]['start_time']).total_seconds()\n",
    "        model_stats[model]['avg_time'] = np.mean(model_stats[model]['processing_times'])\n",
    "        model_stats[model]['min_time'] = np.min(model_stats[model]['processing_times'])\n",
    "        model_stats[model]['max_time'] = np.max(model_stats[model]['processing_times'])\n",
    "        model_stats[model]['median_time'] = np.median(model_stats[model]['processing_times'])\n",
    "        model_stats[model]['avg_length'] = np.mean(model_stats[model]['summary_lengths'])\n",
    "        model_stats[model]['min_length'] = np.min(model_stats[model]['summary_lengths'])\n",
    "        model_stats[model]['max_length'] = np.max(model_stats[model]['summary_lengths'])\n",
    "        model_stats[model]['median_length'] = np.median(model_stats[model]['summary_lengths'])\n",
    "\n",
    "# Process Ollama models\n",
    "process_model_summaries(ollamaModels, use_openai=False)\n",
    "\n",
    "# Process OpenAI models\n",
    "process_model_summaries(openAiModels, use_openai=True)\n",
    "\n",
    "# Create summary DataFrame\n",
    "summary_stats = pd.DataFrame({\n",
    "    'Model': list(model_stats.keys()),\n",
    "    'Total Time (s)': [stats['total_time'] for stats in model_stats.values()],\n",
    "    'Avg Time (s)': [stats['avg_time'] for stats in model_stats.values()],\n",
    "    'Min Time (s)': [stats['min_time'] for stats in model_stats.values()],\n",
    "    'Max Time (s)': [stats['max_time'] for stats in model_stats.values()],\n",
    "    'Median Time (s)': [stats['median_time'] for stats in model_stats.values()],\n",
    "    'Avg Length': [stats['avg_length'] for stats in model_stats.values()],\n",
    "    'Min Length': [stats['min_length'] for stats in model_stats.values()],\n",
    "    'Max Length': [stats['max_length'] for stats in model_stats.values()],\n",
    "    'Median Length': [stats['median_length'] for stats in model_stats.values()]\n",
    "})\n",
    "\n",
    "# Log both tables to wandb\n",
    "wandb.log({\n",
    "    \"summaries\": wandb.Table(dataframe=modelComparison),\n",
    "    \"model_stats\": wandb.Table(dataframe=summary_stats)\n",
    "})\n",
    "\n",
    "# Display the summary statistics\n",
    "print(\"\\nModel Performance Statistics:\")\n",
    "print(summary_stats.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for model in ollamaModels:\n",
    "#     llm = get_llm(use_openai=False, model_name=model)\n",
    "    \n",
    "#     # iterate over the rows of the dataframe\n",
    "#     for index, row in df.iterrows():\n",
    "#         # get the raw content\n",
    "#         raw_content = row['raw_content']\n",
    "#         # summarize the raw content\n",
    "#         summary = llm.invoke(prompt + \"\\n\" + raw_content)\n",
    "#         # add the summary to the dataframe\n",
    "#         df.at[index, model + '_summary'] = summary\n",
    "\n",
    "# for model in openAiModels:\n",
    "#     llm = get_llm(use_openai=True)\n",
    "#     # iterate over the rows of the dataframe\n",
    "#     for index, row in df.iterrows():\n",
    "#         # get the raw content\n",
    "#         raw_content = row['raw_content']\n",
    "#         # summarize the raw content\n",
    "#         summary = llm.invoke(prompt + \"\\n\" + raw_content)\n",
    "#         # add the summary to the dataframe\n",
    "#         df.at[index, model + '_summary'] = summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # select df columns: partner1, partner2, raw_content, gemma3:1b_summary, llama3.2:latest_summary, phi4:latest_summary, gpt-4o_summary and save as modelComparison data frame\n",
    "# modelComparison = df[['partner1', 'partner2', 'raw_content', 'gemma3:1b_summary', 'llama3.2:latest_summary', 'phi4:latest_summary', 'gpt-4o_summary']].copy()\n",
    "\n",
    "# # Convert AIMessage objects to strings\n",
    "# for col in modelComparison.columns:\n",
    "#     if col.endswith('_summary'):\n",
    "#         modelComparison[col] = modelComparison[col].apply(lambda x: x.content if hasattr(x, 'content') else str(x))\n",
    "\n",
    "# # Log to wandb\n",
    "# wandb.log({\"summaries\": wandb.Table(dataframe=modelComparison)})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI_agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
